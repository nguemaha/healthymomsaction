{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc6dcc9-0fb2-4dad-8f56-34cabfd29281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62d950-8b84-44fa-8637-a9bf2578c05e",
   "metadata": {},
   "source": [
    "#### This code read file column wise, which leads to problems where some columns have more rows that others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "effb56f7-e817-43e0-a4bb-02e9c2473725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import base64\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "HOME_DIR = os.path.expanduser(\"~\")\n",
    "load_dotenv(f\"{HOME_DIR}/.env\")\n",
    "\n",
    "# Step 1: Define the structured response model\n",
    "class TableData(BaseModel):\n",
    "    Country: List[str]\n",
    "    OrgName: List[str]\n",
    "    OrgType: List[str]\n",
    "    Description: List[str]\n",
    "    Amount: List[str]\n",
    "\n",
    "\n",
    "# Step 2: Load API client\n",
    "def get_openai_client() -> OpenAI:\n",
    "    return OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Step 3: Read and encode image to base64\n",
    "def encode_image_to_base64(image_path: str) -> str:\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Step 4: Build the message for GPT\n",
    "def build_vision_prompt(prompt: str, base64_image: str) -> list:\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "# Step 5: Define the main prompt text\n",
    "def get_default_prompt() -> str:\n",
    "    prompt = \"\"\"\n",
    "        You are a data extraction assistant. Your task is to extract structured tabular data from an image of a table.\n",
    "        The image contains rows with the following five columns:\n",
    "            - Country\n",
    "            - Partner Organization Name\n",
    "            - Organization Type (e.g., NGO, Government)\n",
    "            - Project Description\n",
    "            - Amount (USD)\n",
    "        \n",
    "        Follow these instructions:\n",
    "        - Read the entire table from the image.\n",
    "        - Accurately extract the text in each row into a list.\n",
    "        - Make sure that all columns have thesame number of rows.\n",
    "        - Remove any artifacts, duplicated text, or OCR errors.\n",
    "        - If any data is unclear or incomplete, make a best-effort inference and mark it with [inferred]. \n",
    "        - Do not guess numerical values.\n",
    "        - Only return the JSON object matching the format.\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Step 6: Make structured GPT call\n",
    "def parse_table_data_from_image(image_path: str, model_name=\"gpt-4o\") -> TableData:\n",
    "    client = get_openai_client() \n",
    "    base64_img = encode_image_to_base64(image_path)\n",
    "    prompt = get_default_prompt()\n",
    "    messages = build_vision_prompt(prompt, base64_img)\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        response_format=TableData\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47395e40-232f-49f0-860d-3da48d8a1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "image_path = f\"../data/unfpa_partners/p{i}.png\"\n",
    "response = parse_table_data_from_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "886a4eed-fb3e-4927-9d90-96c8bc27b5ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m table_dict = response.model_dump()\n\u001b[32m      2\u001b[39m columns = [\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCountry\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOrgName\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAmount\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df = pd.DataFrame(table_dict)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#df.columns = columns\u001b[39;00m\n\u001b[32m     11\u001b[39m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\agentsenv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\agentsenv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\agentsenv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = _extract_index(arrays)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\agentsenv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "table_dict = response.model_dump()\n",
    "columns = [\n",
    "    \"Country\",\n",
    "    \"OrgName\",\n",
    "    \"OrgType\",\n",
    "    \"Description\",\n",
    "    \"Amount\"\n",
    "]\n",
    "df = pd.DataFrame(table_dict)\n",
    "#df.columns = columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "334f17d5-1b16-453c-b499-b23191730972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'../data/unfpa_partners/p{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8a904-9b2a-415b-9764-10418a85715d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
